SOLVER:
  gpu: 0,
  run: train

  logdir: logs/shapenet_vae/vae
  max_epoch: 200
  test_every_epoch: 5
  log_per_iter: 50
  ckpt_num: 10
  port: 20001

  # optimizer
  type: adamw
  weight_decay: 0.01  # default value of adamw
  lr: 0.0001           # default value of adamw
  rand_seed: 0
  enable_amp: True

  # learning rate
  lr_type: constant
  # lr_type: step_warmup
  # warmup_epoch: 20
  # milestones: (200,)
  step_size: (160,240)

  # sdf
  resolution: 256       # the resolution used for marching cubes
  save_sdf: False       # save the sdfs in evaluation
  sdf_scale: 0.9        # the scale of sdfs

DATA:
  train:
    name: &name shapenet_vae

    # octree building
    depth: &depth 8
    full_depth: &full_depth 3
    point_scale: &point_scale 0.5  # the scale of point clouds

    # sdf & color samples
    volume_sample_num: &volume_sample_num 10000
    surface_sample_num: &surface_sample_num 10000
    # max_points: 120000

    # no data augmentation
    distort: &distort False

    # data loading
    location: &location data/ShapeNet/dataset_new
    filelist: &filelist data/ShapeNet/filelist/train_airplane.txt
    load_pointcloud: &load_pointcloud True
    load_sdf: &load_sdf False
    batch_size: 1
    shuffle: True

  test:
    name: *name

    # octree building
    depth: *depth
    full_depth: *full_depth
    point_scale: *point_scale

    # sdf & color samples
    volume_sample_num: *volume_sample_num
    surface_sample_num: *surface_sample_num

    # no data augmentation
    distort: *distort

    # data loading
    location: *location
    filelist: data/ShapeNet/filelist/test_airplane.txt
    batch_size: 1
    load_pointcloud: *load_pointcloud
    load_sdf: *load_sdf
    shuffle: False

MODEL:
  depth: *depth
  full_depth: *full_depth
  depth_stop: 6
  vqvae_ckpt: saved_ckpt/vqvae_model.pth
  find_unused_parameters: True
  model_name: MAR

  VQVAE:
    name: vqvae

    in_channels: 4
    embedding_sizes: 128
    embedding_channels: 256
    quantizer_type: group-project
    quantizer_group: 4
    feature: ND
  
  GPT:
    num_embed: 768
    num_heads: 8
    num_blocks: 16
    num_classes: 1
    split_size: 2
    vq_size: 128
    patch_size: 2048
    dilation: 2
    drop_rate: 0.1
    pos_emb_type: SinPosEmb
    use_checkpoint: True
    use_swin: True
    num_vq_blocks: 2
    mask_ratio_min: 0.7
    remask_stage: 0.7
    start_temperature: [1.4, 1.5, 0.5, 0.5]
    num_iters: [64, 128, 128, 256]
    condition_type: None
  

LOSS:
  name: shapenet_vae_loss
  loss_type: sdf_reg_loss
  vq_weight: 0.1
